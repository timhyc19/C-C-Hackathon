{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f7bb892c",
      "metadata": {
        "id": "f7bb892c"
      },
      "source": [
        "### Reading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "436aeec2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello\n"
          ]
        }
      ],
      "source": [
        "print(\"Hello\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8001a2b4",
      "metadata": {
        "id": "8001a2b4",
        "outputId": "8540355c-8c8b-4fdb-da25-166b192799f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size 3969\n",
            "Test size 997\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>medical_specialty</th>\n",
              "      <th>transcription</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Emergency Room Reports</td>\n",
              "      <td>REASON FOR THE VISIT:,  Very high PT/INR.,HIST...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Surgery</td>\n",
              "      <td>PREOPERATIVE DIAGNOSIS:,  Acetabular fracture ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Surgery</td>\n",
              "      <td>NAME OF PROCEDURE,1.  Selective coronary angio...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         medical_specialty                                      transcription  \\\n",
              "0   Emergency Room Reports  REASON FOR THE VISIT:,  Very high PT/INR.,HIST...   \n",
              "1                  Surgery  PREOPERATIVE DIAGNOSIS:,  Acetabular fracture ...   \n",
              "2                  Surgery  NAME OF PROCEDURE,1.  Selective coronary angio...   \n",
              "\n",
              "   labels  \n",
              "0       0  \n",
              "1       1  \n",
              "2       1  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv(\"new_train.csv\", index_col=0)\n",
        "test_df = pd.read_csv(\"new_test.csv\", index_col=0)\n",
        "\n",
        "print(\"Train size\", len(train_df))\n",
        "print(\"Test size\", len(test_df))\n",
        "train_df.head(n=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b326d130",
      "metadata": {
        "id": "b326d130"
      },
      "source": [
        "### Train Set Label Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c349df00",
      "metadata": {
        "id": "c349df00",
        "outputId": "16247674-c202-4ec2-c317-4ea2c2a1bbda",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              " Surgery                          863\n",
              " Consult - History and Phy.       410\n",
              " Cardiovascular / Pulmonary       309\n",
              " Orthopedic                       289\n",
              " Radiology                        213\n",
              " General Medicine                 209\n",
              " Gastroenterology                 176\n",
              " Neurology                        170\n",
              " SOAP / Chart / Progress Notes    135\n",
              " Urology                          134\n",
              " Obstetrics / Gynecology          123\n",
              " Discharge Summary                 87\n",
              " ENT - Otolaryngology              82\n",
              " Neurosurgery                      71\n",
              " Hematology - Oncology             68\n",
              " Ophthalmology                     67\n",
              " Emergency Room Reports            63\n",
              " Nephrology                        63\n",
              " Pediatrics - Neonatal             55\n",
              " Pain Management                   54\n",
              " Psychiatry / Psychology           45\n",
              " Office Notes                      38\n",
              " Podiatry                          35\n",
              " Dermatology                       21\n",
              " Dentistry                         21\n",
              " Cosmetic / Plastic Surgery        19\n",
              " Letters                           19\n",
              " Endocrinology                     16\n",
              " Physical Medicine - Rehab         16\n",
              " Bariatrics                        15\n",
              " IME-QME-Work Comp etc.            12\n",
              " Chiropractic                      12\n",
              " Sleep Medicine                    12\n",
              " Diets and Nutritions               9\n",
              " Speech - Language                  8\n",
              " Autopsy                            7\n",
              " Hospice - Palliative Care          6\n",
              " Allergy / Immunology               6\n",
              " Rheumatology                       6\n",
              " Lab Medicine - Pathology           5\n",
              "Name: medical_specialty, dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df[\"medical_specialty\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9df8c8f3",
      "metadata": {
        "id": "9df8c8f3"
      },
      "source": [
        "### Sample Transcription"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4b4b315a",
      "metadata": {
        "id": "4b4b315a",
        "outputId": "dca6a8e9-189d-41a6-b0d4-7a7723fb85c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('REASON FOR THE VISIT:,  Very high PT/INR.,HISTORY: , The patient is an '\n",
            " '81-year-old lady whom I met last month when she came in with pneumonia and '\n",
            " 'CHF.  She was noticed to be in atrial fibrillation, which is a chronic '\n",
            " 'problem for her.  She did not want to have Coumadin started because she said '\n",
            " 'that she has had it before and the INR has had been very difficult to '\n",
            " 'regulate to the point that it was dangerous, but I convinced her to restart '\n",
            " 'the Coumadin again.  I gave her the Coumadin as an outpatient and then the '\n",
            " 'INR was found to be 12.  So, I told her to come to the emergency room to get '\n",
            " 'vitamin K to reverse the anticoagulation.,PAST MEDICAL HISTORY:,1.  '\n",
            " 'Congestive heart failure.,2.  Renal insufficiency.,3.  Coronary artery '\n",
            " 'disease.,4.  Atrial fibrillation.,5.  COPD.,6.  Recent pneumonia.,7.  '\n",
            " 'Bladder cancer.,8.  History of ruptured colon.,9.  Myocardial '\n",
            " 'infarction.,10.  Hernia repair.,11.  Colon resection.,12.  Carpal tunnel '\n",
            " 'repair.,13.  Knee surgery.,MEDICATIONS:,1.  Coumadin.,2.  Simvastatin.,3.  '\n",
            " 'Nitrofurantoin.,4.  Celebrex.,5.  Digoxin.,6.  Levothyroxine.,7.  '\n",
            " 'Vicodin.,8.  Triamterene and hydrochlorothiazide.,9.  Carvedilol.,SOCIAL '\n",
            " 'HISTORY:  ,She does not smoke and she does not drink.,PHYSICAL '\n",
            " 'EXAMINATION:,GENERAL:  Lady in no distress.,VITAL SIGNS:  Blood pressure '\n",
            " '100/46, pulse of 75, respirations 12, and temperature 98.2.,HEENT:  Head is '\n",
            " 'normal.,NECK:  Supple.,LUNGS:  Clear to auscultation and percussion.,HEART:  '\n",
            " 'No S3, no S4, and no murmurs.,ABDOMEN:  Soft.,EXTREMITIES:  Lower '\n",
            " 'extremities, no edema.,ASSESSMENT:,1.  Atrial fibrillation.,2.  '\n",
            " 'Coagulopathy, induced by Coumadin.,PLAN: , Her INR at the office was 12.  I '\n",
            " 'will repeat it, and if it is still elevated, I will give vitamin K 10 mg in '\n",
            " '100 mL of D5W and then send her home and repeat the PT/INR next week.  I '\n",
            " 'believe at this time that it is too risky to use Coumadin in her case '\n",
            " 'because of her age and comorbidities, the multiple medications that she '\n",
            " 'takes and it is very difficult to keep an adequate level of anticoagulation '\n",
            " 'that is safe for her.  She is prone to a fall and this would be a big '\n",
            " 'problem.  We will use one aspirin a day instead of the anticoagulation.  She '\n",
            " 'is aware of the risk of stroke, but she is very scared of the '\n",
            " 'anticoagulation with Coumadin and does not want to use the Coumadin at this '\n",
            " 'time and I understand.  We will see her as an outpatient.')\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "pprint(train_df.transcription[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f1b6f4d",
      "metadata": {
        "id": "0f1b6f4d"
      },
      "source": [
        "### Sample Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "68977658",
      "metadata": {
        "id": "68977658"
      },
      "outputs": [],
      "source": [
        "from datasets.dataset_dict import DatasetDict\n",
        "from datasets import Dataset\n",
        "from torch import nn\n",
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "3e142223",
      "metadata": {
        "id": "3e142223"
      },
      "outputs": [],
      "source": [
        "unique_classes = train_df[\"medical_specialty\"].unique()\n",
        "\n",
        "# idx_2_class = {i: s for i, s in enumerate(unique_classes)}\n",
        "# class_2_idx = {s: i for i, s in enumerate(unique_classes)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "cac5d380",
      "metadata": {
        "id": "cac5d380"
      },
      "outputs": [],
      "source": [
        "# train_df[\"labels\"] = train_df[\"medical_specialty\"].apply(lambda s: class_2_idx[s])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "233a4365",
      "metadata": {
        "id": "233a4365"
      },
      "outputs": [],
      "source": [
        "train_train_df, train_test_df = \\\n",
        "    train_test_split(\n",
        "    train_df,\n",
        "    test_size=0.3,\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "449f16bd",
      "metadata": {
        "id": "449f16bd"
      },
      "outputs": [],
      "source": [
        "ds_dict = {\n",
        "    'train': Dataset.from_pandas(train_train_df),\n",
        "    'val': Dataset.from_pandas(train_test_df),\n",
        "    \"test\": Dataset.from_pandas(test_df)\n",
        "}\n",
        "\n",
        "ds = DatasetDict(ds_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "a995f402",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "3a6ee68ccb5844bf8a7ef1736274e442",
            "12d72b7eadcf485aa898b4fcb9c89d60",
            "00307d96c1f74a10a7447c60d27b3e47"
          ]
        },
        "id": "a995f402",
        "outputId": "f32df782-5270-4125-b582-88aa98c2cd87",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bdb42f2525be4661ad9d1c2be30e2b00",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bfb96ea429564eeda044e4a09ecc6253",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a807818a37484955a49827822f235366",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cbbb551f0ebb438e8efa2f763c3ea430",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35a10765f30a47c7a89e91205153d82f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74b216bd23b0443abeff7a3f4a5fe1ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b661378b31d423b8c050cbf64423306",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize_text(texts):\n",
        "    return tokenizer(texts[\"transcription\"], truncation=True, padding=True, max_length=256)\n",
        "\n",
        "ds[\"train\"] = ds[\"train\"].map(tokenize_text, batched=True)\n",
        "ds[\"val\"] = ds[\"val\"].map(tokenize_text, batched=True)\n",
        "ds[\"test\"] = ds[\"test\"].map(tokenize_text, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "fa6c4319",
      "metadata": {
        "id": "fa6c4319",
        "outputId": "780ee179-90d5-4a67-cb43-fe535c0cc0af"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95900ce6866e426a90aab742c4a45e5f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=len(unique_classes)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e22ca876",
      "metadata": {
        "id": "e22ca876"
      },
      "source": [
        "### Evaluation Metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "1f26fe53",
      "metadata": {
        "id": "1f26fe53"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    f1 = f1_score(labels, preds, average=\"macro\")\n",
        "    return {\"f1\": f1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "414f5205",
      "metadata": {
        "id": "414f5205"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "logging_steps = len(train_train_df) // batch_size\n",
        "output_dir = \"hf_trainer\"\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "     num_train_epochs=5,\n",
        "     learning_rate=2e-5,\n",
        "     per_device_train_batch_size=batch_size,\n",
        "     per_device_eval_batch_size=batch_size,\n",
        "     weight_decay=0.01,\n",
        "     evaluation_strategy=\"epoch\",\n",
        "     logging_steps=logging_steps,\n",
        "     push_to_hub=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "994876be",
      "metadata": {
        "id": "994876be"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=ds['train'],\n",
        "    eval_dataset=ds['val'],\n",
        "    tokenizer=tokenizer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "c8cfca94",
      "metadata": {
        "id": "c8cfca94",
        "outputId": "42bd5619-878a-4bd7-c6cc-ba14d5d632c9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: transcription, medical_specialty, __index_level_0__. If transcription, medical_specialty, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 2778\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 435\n",
            "  Number of trainable parameters = 66984232\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5223c0f38c71463d98905b2e68746c9b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/435 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0a6603a",
      "metadata": {
        "id": "e0a6603a"
      },
      "source": [
        "### Making Inference on the Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3bc4a1d",
      "metadata": {
        "id": "d3bc4a1d",
        "outputId": "626e4d0f-85df-47bd-9cd8-b43ec11c6840"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['transcription', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 997\n",
              "})"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0d1f4da",
      "metadata": {
        "id": "d0d1f4da",
        "outputId": "97e40aa9-a296-4fef-c0a2-7d2f30789e72"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, transcription. If __index_level_0__, transcription are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 997\n",
            "  Batch size = 32\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pred_y = trainer.predict(ds[\"test\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0411c232",
      "metadata": {
        "id": "0411c232"
      },
      "outputs": [],
      "source": [
        "a = pd.Series(pred_y.predictions.argmax(axis=1))\n",
        "a.name = \"Expected\"\n",
        "a.to_csv(\"predictions.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
